{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97fead0b",
   "metadata": {},
   "source": [
    "# EXTRACT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5e693d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-20 12:36:34,886 - INFO - \n",
      " ----------------------------------------------------------------------------------\n",
      "2025-08-20 12:36:34,889 - INFO - \n",
      " Executando Rotina - RELATORIO ATIVACOES PENDENTES\n",
      "2025-08-20 12:36:34,908 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-20 12:36:35,842 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-20 12:36:37,169 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-20 12:36:38,467 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-20 12:36:39,400 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-20 12:36:41,210 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-20 12:36:43,062 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-20 12:36:44,861 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-20 12:36:46,759 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-20 12:36:48,591 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-20 12:36:50,458 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-20 12:36:52,881 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-20 12:36:54,823 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-20 12:36:56,775 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-20 12:36:58,707 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-20 12:37:00,563 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-20 12:37:02,372 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-20 12:37:04,329 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-20 12:37:06,121 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-20 12:37:07,957 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-20 12:37:09,856 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-20 12:37:11,706 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-20 12:37:13,542 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-20 12:37:15,429 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-20 12:37:17,305 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-20 12:37:19,157 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-20 12:37:21,010 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-20 12:37:22,863 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-20 12:37:23,672 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-20 12:37:24,477 - INFO - Created CTAS table \"silver\".\"temp_table_b7e12e0d1eb84fc7988759ea5b1fd90f\"\n",
      "2025-08-20 12:37:24,489 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-20 12:37:25,431 - INFO - Skipping checksum validation. Response did not contain one of the following algorithms: ['crc32', 'sha1', 'sha256'].\n",
      "2025-08-20 12:37:25,446 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-20 12:37:26,799 - INFO - Skipping checksum validation. Response did not contain one of the following algorithms: ['crc32', 'sha1', 'sha256'].\n",
      "2025-08-20 12:37:26,804 - INFO - Skipping checksum validation. Response did not contain one of the following algorithms: ['crc32', 'sha1', 'sha256'].\n",
      "2025-08-20 12:37:26,821 - INFO - Skipping checksum validation. Response did not contain one of the following algorithms: ['crc32', 'sha1', 'sha256'].\n",
      "2025-08-20 12:37:26,838 - INFO - Skipping checksum validation. Response did not contain one of the following algorithms: ['crc32', 'sha1', 'sha256'].\n",
      "2025-08-20 12:37:27,538 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-20 12:37:28,847 - INFO - \n",
      " ----------------------------------------------------------------------------------\n",
      "2025-08-20 12:37:28,847 - INFO - \n",
      " Relatorio ativacoes (Vivante)  - Dados Extraidos com sucesso!\n",
      "2025-08-20 12:37:28,862 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-20 12:37:29,647 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-20 12:37:31,056 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-20 12:37:32,584 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-20 12:37:33,429 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-20 12:37:35,279 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-20 12:37:37,174 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-20 12:37:39,038 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-20 12:37:40,888 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-20 12:37:42,737 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-20 12:37:44,579 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-20 12:37:46,406 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-20 12:37:48,287 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-20 12:37:50,104 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-20 12:37:51,953 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-20 12:37:53,786 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-20 12:37:55,609 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-20 12:37:57,446 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-20 12:37:58,287 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-20 12:37:59,054 - INFO - Created CTAS table \"silver\".\"temp_table_6786d9b5dccd4a89a0221d71e5f181c1\"\n",
      "2025-08-20 12:37:59,064 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-20 12:37:59,909 - INFO - Skipping checksum validation. Response did not contain one of the following algorithms: ['crc32', 'sha1', 'sha256'].\n",
      "2025-08-20 12:37:59,955 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-20 12:38:01,237 - INFO - Skipping checksum validation. Response did not contain one of the following algorithms: ['crc32', 'sha1', 'sha256'].\n",
      "2025-08-20 12:38:01,274 - INFO - Skipping checksum validation. Response did not contain one of the following algorithms: ['crc32', 'sha1', 'sha256'].\n",
      "2025-08-20 12:38:01,304 - INFO - Skipping checksum validation. Response did not contain one of the following algorithms: ['crc32', 'sha1', 'sha256'].\n",
      "2025-08-20 12:38:01,306 - INFO - Skipping checksum validation. Response did not contain one of the following algorithms: ['crc32', 'sha1', 'sha256'].\n",
      "2025-08-20 12:38:01,813 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-20 12:38:02,971 - INFO - \n",
      " ----------------------------------------------------------------------------------\n",
      "2025-08-20 12:38:02,971 - INFO - \n",
      " Relatorio cancelamentos  - Dados Extraidos com sucesso!\n",
      "2025-08-20 12:38:02,990 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-20 12:38:03,737 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-20 12:38:05,010 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-20 12:38:06,282 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-20 12:38:07,389 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-20 12:38:09,224 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-20 12:38:11,063 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-20 12:38:12,876 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-20 12:38:14,873 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-20 12:38:16,837 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-20 12:38:18,656 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-20 12:38:20,510 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-20 12:38:22,329 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-20 12:38:24,142 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-20 12:38:25,946 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-20 12:38:27,760 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-20 12:38:29,558 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-20 12:38:31,376 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-20 12:38:32,217 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-20 12:38:32,968 - INFO - Created CTAS table \"silver\".\"temp_table_3d286a2165fe404bb0246dd8ac1a1b70\"\n",
      "2025-08-20 12:38:32,986 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-20 12:38:33,835 - INFO - Skipping checksum validation. Response did not contain one of the following algorithms: ['crc32', 'sha1', 'sha256'].\n",
      "2025-08-20 12:38:33,850 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-20 12:38:35,118 - INFO - Skipping checksum validation. Response did not contain one of the following algorithms: ['crc32', 'sha1', 'sha256'].\n",
      "2025-08-20 12:38:35,155 - INFO - Skipping checksum validation. Response did not contain one of the following algorithms: ['crc32', 'sha1', 'sha256'].\n",
      "2025-08-20 12:38:35,175 - INFO - Skipping checksum validation. Response did not contain one of the following algorithms: ['crc32', 'sha1', 'sha256'].\n",
      "2025-08-20 12:38:35,194 - INFO - Skipping checksum validation. Response did not contain one of the following algorithms: ['crc32', 'sha1', 'sha256'].\n",
      "2025-08-20 12:38:36,651 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-08-20 12:38:37,834 - INFO - \n",
      " ----------------------------------------------------------------------------------\n",
      "2025-08-20 12:38:37,834 - INFO - \n",
      " Relatorio conferência  - Dados Extraidos com sucesso!\n"
     ]
    }
   ],
   "source": [
    "import awswrangler as awr\n",
    "import logging\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,  # Exibe mensagens a partir de INFO\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "    handlers=[\n",
    "        logging.StreamHandler()  # Garante logs no console\n",
    "    ]\n",
    ")\n",
    "\n",
    "logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "logging.info('\\n Executando Rotina - RELATORIO ATIVACOES PENDENTES')\n",
    "\n",
    "class Extract:\n",
    "\n",
    "    # FUNÇÃO CONSTRUTORA\n",
    "    def __init__(self):\n",
    "        #self.path = os.path.dirname(__file__) #atributo de instância que obtém o caminho do diretório dirname\n",
    "        self.path = r\"C:\\Users\\raphael.almeida\\Documents\\Processos\\placas_acompanhamento\"\n",
    "\n",
    "    # FUNÇÃO PARA EXTRAÇÃO DE DADOS DE: ATIVAÇÕES\n",
    "    def extract_all_ativacoes(self):\n",
    "        \"\"\"\n",
    "        Retorna um DataFrame com os dados de ativações.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            dir_query = os.path.join(self.path, 'sql', 'all_boards_ATIVOS.sql')\n",
    "            with open(dir_query, 'r') as file:\n",
    "                query = file.read()\n",
    "            df_ativacoes = awr.athena.read_sql_query(query, database='silver')\n",
    "            logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "            logging.info('\\n Relatorio ativacoes (Vivante)  - Dados Extraidos com sucesso!')\n",
    "            return df_ativacoes\n",
    "        except Exception as e:\n",
    "            logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "            logging.info(f'\\n Falha ao Extrair relatorio ativacoes (Viavante): {e}')\n",
    "            return None\n",
    "\n",
    "    # FUNÇÃO PARA EXTRAÇÃO DE DADOS DE: CANCELAMENTO INTEGRAL\n",
    "    def extract_all_cancelamentos(self):\n",
    "        \"\"\"\n",
    "        Retorna um DataFrame com os dados de cancelamentos.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            dir_query = os.path.join(self.path, 'sql', 'all_boards_CANCELADOS.sql')\n",
    "            with open(dir_query, 'r') as file:\n",
    "                query = file.read()\n",
    "            df_cancelamentos = awr.athena.read_sql_query(query, database='silver')\n",
    "            logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "            logging.info('\\n Relatorio cancelamentos  - Dados Extraidos com sucesso!')\n",
    "            return df_cancelamentos\n",
    "        except Exception as e:\n",
    "            logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "            logging.info(f'\\n Falha ao Extrair relatorio cancelamentos: {e}')\n",
    "            return None\n",
    "\n",
    "    # FUNÇÃO PARA EXTRAÇÃO DE DADOS DE: CONFERÊNCIA\n",
    "    def extract_conf_boards(self):\n",
    "        \"\"\"\n",
    "        Retorna um DataFrame com os dados de conferência.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            dir_query = os.path.join(self.path, 'sql', 'listagem_mestra.sql')\n",
    "            with open(dir_query, 'r') as file:\n",
    "                query = file.read()\n",
    "            df_conferencia = awr.athena.read_sql_query(query, database='silver')\n",
    "            logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "            logging.info('\\n Relatorio conferência  - Dados Extraidos com sucesso!')\n",
    "            return df_conferencia\n",
    "        except Exception as e:\n",
    "            logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "            logging.info(f'\\n Falha ao Extrair relatorio conferência: {e}')\n",
    "            return None\n",
    "\n",
    "# Exemplo de como declarar as variáveis dos returns dos métodos para usar depois:\n",
    "# Basta instanciar a classe e chamar os métodos, atribuindo o retorno a variáveis:\n",
    "\n",
    "extract = Extract()\n",
    "df_ativacoes = extract.extract_all_ativacoes()\n",
    "df_cancelamentos = extract.extract_all_cancelamentos()\n",
    "df_conferencia = extract.extract_conf_boards()\n",
    "\n",
    "# Agora você pode usar df_ativacoes, df_cancelamentos, df_conferencia normalmente no seu código.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1d536d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>placa</th>\n",
       "      <th>chassi</th>\n",
       "      <th>id_placa</th>\n",
       "      <th>id_veiculo</th>\n",
       "      <th>id_carroceria</th>\n",
       "      <th>matricula</th>\n",
       "      <th>conjunto</th>\n",
       "      <th>unidade</th>\n",
       "      <th>consultor</th>\n",
       "      <th>status</th>\n",
       "      <th>...</th>\n",
       "      <th>empresa</th>\n",
       "      <th>coverage</th>\n",
       "      <th>beneficio</th>\n",
       "      <th>categoria</th>\n",
       "      <th>tipo_categoria</th>\n",
       "      <th>data_ativacao_beneficio</th>\n",
       "      <th>status_beneficio</th>\n",
       "      <th>data_atualizacao</th>\n",
       "      <th>consultor_ativo</th>\n",
       "      <th>id_beneficio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7581</th>\n",
       "      <td>OOM9H35</td>\n",
       "      <td>98PTS47MSKB107595</td>\n",
       "      <td>1827</td>\n",
       "      <td>1827</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>472</td>\n",
       "      <td>500</td>\n",
       "      <td>UNIDADE CUIABA</td>\n",
       "      <td>Isabella Santos</td>\n",
       "      <td>ATIVO</td>\n",
       "      <td>...</td>\n",
       "      <td>Tag</td>\n",
       "      <td>680634</td>\n",
       "      <td>Assistência a Reparos (VEÍCULO)</td>\n",
       "      <td>PESADOS - CAVALO MECÂNICO</td>\n",
       "      <td>DAF - 4%</td>\n",
       "      <td>2025-08-08</td>\n",
       "      <td>ATIVO</td>\n",
       "      <td>2025-08-08</td>\n",
       "      <td>S</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7582</th>\n",
       "      <td>BAW1B34</td>\n",
       "      <td>9BFYEALE7GBL90987</td>\n",
       "      <td>2080</td>\n",
       "      <td>2080</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>473</td>\n",
       "      <td>958</td>\n",
       "      <td>MICRO B - JULIANO DE COSTA</td>\n",
       "      <td>Juliano Costa</td>\n",
       "      <td>ATIVO</td>\n",
       "      <td>...</td>\n",
       "      <td>Tag</td>\n",
       "      <td>690330</td>\n",
       "      <td>Assistência 24 Horas</td>\n",
       "      <td>PESADOS - CAMINHÃO</td>\n",
       "      <td>ATÉ 15 ANOS</td>\n",
       "      <td>2025-08-15</td>\n",
       "      <td>ATIVO</td>\n",
       "      <td>2025-08-19</td>\n",
       "      <td>S</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7583</th>\n",
       "      <td>BAW1B34</td>\n",
       "      <td>9BFYEALE7GBL90987</td>\n",
       "      <td>2080</td>\n",
       "      <td>2080</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>473</td>\n",
       "      <td>958</td>\n",
       "      <td>MICRO B - JULIANO DE COSTA</td>\n",
       "      <td>Juliano Costa</td>\n",
       "      <td>ATIVO</td>\n",
       "      <td>...</td>\n",
       "      <td>Tag</td>\n",
       "      <td>690329</td>\n",
       "      <td>RCF</td>\n",
       "      <td>PESADOS - CAMINHÃO</td>\n",
       "      <td>PADRÃO</td>\n",
       "      <td>2025-08-15</td>\n",
       "      <td>ATIVO</td>\n",
       "      <td>2025-08-19</td>\n",
       "      <td>S</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7584</th>\n",
       "      <td>SDT3C95</td>\n",
       "      <td>9BVRG40D6NE923631</td>\n",
       "      <td>100173</td>\n",
       "      <td>100173</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2</td>\n",
       "      <td>733</td>\n",
       "      <td>UNIDADE CASCAVEL</td>\n",
       "      <td>Thiago Rosa De Figueiredo</td>\n",
       "      <td>ATIVO</td>\n",
       "      <td>...</td>\n",
       "      <td>Tag</td>\n",
       "      <td>687864</td>\n",
       "      <td>Rastreador p/ Veículo</td>\n",
       "      <td>PADRÃO</td>\n",
       "      <td>PADRÃO</td>\n",
       "      <td>2025-08-13</td>\n",
       "      <td>ATIVO</td>\n",
       "      <td>2025-08-13</td>\n",
       "      <td>S</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7585</th>\n",
       "      <td>AKV6G15</td>\n",
       "      <td>9AA07072G3C041923</td>\n",
       "      <td>2978</td>\n",
       "      <td>0</td>\n",
       "      <td>2978</td>\n",
       "      <td>2</td>\n",
       "      <td>733</td>\n",
       "      <td>UNIDADE CASCAVEL</td>\n",
       "      <td>Thiago Rosa De Figueiredo</td>\n",
       "      <td>ATIVO</td>\n",
       "      <td>...</td>\n",
       "      <td>Tag</td>\n",
       "      <td>687862</td>\n",
       "      <td>Assistência a Reparos (R/SR)</td>\n",
       "      <td>GRANELEIRO</td>\n",
       "      <td>PADRÃO - 8%</td>\n",
       "      <td>2025-08-13</td>\n",
       "      <td>ATIVO</td>\n",
       "      <td>2025-08-13</td>\n",
       "      <td>S</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        placa             chassi  id_placa  id_veiculo  id_carroceria  \\\n",
       "7581  OOM9H35  98PTS47MSKB107595      1827        1827           <NA>   \n",
       "7582  BAW1B34  9BFYEALE7GBL90987      2080        2080           <NA>   \n",
       "7583  BAW1B34  9BFYEALE7GBL90987      2080        2080           <NA>   \n",
       "7584  SDT3C95  9BVRG40D6NE923631    100173      100173           <NA>   \n",
       "7585  AKV6G15  9AA07072G3C041923      2978           0           2978   \n",
       "\n",
       "      matricula  conjunto                     unidade  \\\n",
       "7581        472       500              UNIDADE CUIABA   \n",
       "7582        473       958  MICRO B - JULIANO DE COSTA   \n",
       "7583        473       958  MICRO B - JULIANO DE COSTA   \n",
       "7584          2       733            UNIDADE CASCAVEL   \n",
       "7585          2       733            UNIDADE CASCAVEL   \n",
       "\n",
       "                      consultor status  ... empresa coverage  \\\n",
       "7581            Isabella Santos  ATIVO  ...     Tag   680634   \n",
       "7582              Juliano Costa  ATIVO  ...     Tag   690330   \n",
       "7583              Juliano Costa  ATIVO  ...     Tag   690329   \n",
       "7584  Thiago Rosa De Figueiredo  ATIVO  ...     Tag   687864   \n",
       "7585  Thiago Rosa De Figueiredo  ATIVO  ...     Tag   687862   \n",
       "\n",
       "                            beneficio                  categoria  \\\n",
       "7581  Assistência a Reparos (VEÍCULO)  PESADOS - CAVALO MECÂNICO   \n",
       "7582             Assistência 24 Horas         PESADOS - CAMINHÃO   \n",
       "7583                              RCF         PESADOS - CAMINHÃO   \n",
       "7584            Rastreador p/ Veículo                     PADRÃO   \n",
       "7585     Assistência a Reparos (R/SR)                 GRANELEIRO   \n",
       "\n",
       "     tipo_categoria data_ativacao_beneficio  status_beneficio  \\\n",
       "7581       DAF - 4%              2025-08-08             ATIVO   \n",
       "7582    ATÉ 15 ANOS              2025-08-15             ATIVO   \n",
       "7583         PADRÃO              2025-08-15             ATIVO   \n",
       "7584         PADRÃO              2025-08-13             ATIVO   \n",
       "7585    PADRÃO - 8%              2025-08-13             ATIVO   \n",
       "\n",
       "     data_atualizacao consultor_ativo id_beneficio  \n",
       "7581       2025-08-08               S           37  \n",
       "7582       2025-08-19               S           41  \n",
       "7583       2025-08-19               S           40  \n",
       "7584       2025-08-13               S           44  \n",
       "7585       2025-08-13               S           38  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ativacoes[df_ativacoes['empresa'] == 'Tag'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4563010",
   "metadata": {},
   "source": [
    "# TRANSFORM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3eb57fbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\raphael.almeida\\AppData\\Local\\Temp\\ipykernel_2224\\3456991673.py:110: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  df_ativacoes = df_ativacoes.loc[df_ativacoes['beneficio'].str.contains('(CASCO|TERCEIRO|Assistência a reparos)', regex=True, case = False)]\n",
      "2025-08-20 15:04:07,902 - INFO - \n",
      " ----------------------------------------------------------------------------------\n",
      "2025-08-20 15:04:07,902 - INFO - Shape do DataFrame antes do tratamento: (333, 26)\n",
      "C:\\Users\\raphael.almeida\\AppData\\Local\\Temp\\ipykernel_2224\\3456991673.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['status_beneficio'] = 'NOVO'\n",
      "C:\\Users\\raphael.almeida\\AppData\\Local\\Temp\\ipykernel_2224\\3456991673.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['migration_from'] = np.nan\n",
      "C:\\Users\\raphael.almeida\\AppData\\Local\\Temp\\ipykernel_2224\\3456991673.py:73: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'Viavante' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[mask, 'migration_from'] = empresa_penultima\n",
      "2025-08-20 15:04:25,968 - INFO - \n",
      " ----------------------------------------------------------------------------------\n",
      "2025-08-20 15:04:25,968 - INFO - Processamento concluído com sucesso!\n",
      "2025-08-20 15:04:26,151 - INFO - \n",
      " ----------------------------------------------------------------------------------\n",
      "2025-08-20 15:04:26,151 - INFO - Número de registros ativos na carteira tratado com os dados do dia anterior.\n",
      "2025-08-20 15:04:26,214 - INFO - \n",
      " ----------------------------------------------------------------------------------\n",
      "2025-08-20 15:04:26,214 - INFO - Processo final de tratamento de dataframe de ativação realizado com sucesso!\n",
      "2025-08-20 15:04:26,250 - INFO - \n",
      " ----------------------------------------------------------------------------------\n",
      "2025-08-20 15:04:26,250 - INFO - \n",
      " Processo de Transformacao de Dados concluido com sucesso!\n"
     ]
    }
   ],
   "source": [
    "# IMPORTANDO MÓDULOS E PACOTES\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,  # Exibe mensagens a partir de INFO\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "    handlers=[\n",
    "        logging.StreamHandler()  # Garante logs no console\n",
    "    ]\n",
    ")\n",
    "\n",
    "class Transform:\n",
    "\n",
    "    def board_status_treatment(self, df, df_conf):\n",
    "        \"\"\"\n",
    "        Retorna o DataFrame tratado com status_beneficio e migration_from.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            status_filter_list = ['CANCELADO', 'CANCELADA', 'FINALIZADO', 'FINALIZADA', 'NAO RENOVADO']\n",
    "\n",
    "            if df is None or df.empty:\n",
    "                logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "                logging.info('DataFrame vazio, retornando DataFrame vazio')\n",
    "                return pd.DataFrame()\n",
    "\n",
    "            if df_conf is None or df_conf.empty:\n",
    "                logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "                logging.info('DataFrame de conferência vazio, retornando DataFrame original')\n",
    "                return df\n",
    "\n",
    "            required_columns = ['placa', 'chassi', 'empresa', 'status']\n",
    "            missing_columns = [col for col in required_columns if col not in df.columns]\n",
    "            if missing_columns:\n",
    "                logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "                logging.info(f'Colunas necessárias ausentes no DataFrame: {missing_columns}')\n",
    "                return df\n",
    "\n",
    "            logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "            logging.info(f'Shape do DataFrame antes do tratamento: {df.shape}')\n",
    "\n",
    "            df['status_beneficio'] = 'NOVO'\n",
    "            df['migration_from'] = np.nan\n",
    "\n",
    "            df_conf_grouped = df_conf.groupby(['chassi', 'beneficio']).agg({\n",
    "                'empresa': list,\n",
    "                'data_ativacao_beneficio': list,\n",
    "                'status_beneficio': list\n",
    "            }).reset_index()\n",
    "\n",
    "            conf_dict = df_conf_grouped.set_index(['chassi', 'beneficio']).to_dict('index')\n",
    "\n",
    "            for chassi, beneficio in df[['chassi', 'beneficio']].drop_duplicates().values:\n",
    "                if (chassi, beneficio) in conf_dict:\n",
    "                    conf_data = conf_dict[(chassi, beneficio)]\n",
    "\n",
    "                    if len(conf_data['empresa']) > 1:\n",
    "                        dates = sorted([d for d in conf_data['data_ativacao_beneficio'] if pd.notna(d)])\n",
    "\n",
    "                        if len(dates) > 1:\n",
    "                            penultima_data = dates[-2]\n",
    "                            idx_penultima = conf_data['data_ativacao_beneficio'].index(penultima_data)\n",
    "                            status_penultimo = conf_data['status_beneficio'][idx_penultima]\n",
    "                            empresa_penultima = conf_data['empresa'][idx_penultima]\n",
    "\n",
    "                            mask = (df['chassi'] == chassi) & (df['beneficio'] == beneficio)\n",
    "\n",
    "                            if status_penultimo not in status_filter_list:\n",
    "                                if empresa_penultima != df.loc[mask, 'empresa'].iloc[0]:\n",
    "                                    df.loc[mask, 'status_beneficio'] = 'MIGRAÇÃO'\n",
    "                                    df.loc[mask, 'migration_from'] = empresa_penultima\n",
    "                                else:\n",
    "                                    df.loc[mask, 'status_beneficio'] = 'RENOVAÇÃO'\n",
    "                            else:\n",
    "                                df.loc[mask, 'status_beneficio'] = 'REATIVAÇÃO'\n",
    "\n",
    "            logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "            logging.info(f'Processamento concluído com sucesso!')\n",
    "\n",
    "            return df\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "            logging.info(f'Falha no tratamento de status das placas ativadas: {str(e)}')\n",
    "            return df\n",
    "\n",
    "    def transforming_files(self, df_ativacoes, df_cancelamentos, df_conferencia):\n",
    "        \"\"\"\n",
    "        Retorna os DataFrames transformados de ativações e cancelamentos.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            today = dt.date.today()\n",
    "            yesterday = today - dt.timedelta(days=1)\n",
    "            friday = today - dt.timedelta(days=3)\n",
    "            df_final_ativacoes = pd.DataFrame()\n",
    "\n",
    "            # Tratamento dos benefícios e filtragem\n",
    "            try:\n",
    "                df_ativacoes['data_ativacao_beneficio'] = pd.to_datetime(df_ativacoes['data_ativacao_beneficio']).dt.date\n",
    "                df_ativacoes['beneficio'] = df_ativacoes['beneficio'].replace(\n",
    "                    'REPARAÇÃO OU REPOSIÇÃO DO VEÍCULO', 'CASCO (VEÍCULO)'\n",
    "                ).replace(\n",
    "                    'REPARAÇÃO OU REPOSIÇÃO DO (SEMI)REBOQUE', 'CASCO (R/SR)'\n",
    "                ).replace(\n",
    "                    'REPARAÇÃO OU REPOSIÇÃO DO COMPLEMENTO', 'CASCO (COMPLEMENTO)'\n",
    "                )\n",
    "                df_ativacoes['migration_from'] = np.nan\n",
    "                df_ativacoes = df_ativacoes.loc[df_ativacoes['beneficio'].str.contains('(CASCO|TERCEIRO|Assistência a reparos)', regex=True, case = False)]\n",
    "\n",
    "                df_conferencia['beneficio'] = df_conferencia['beneficio'].replace(\n",
    "                    'REPARAÇÃO OU REPOSIÇÃO DO VEÍCULO', 'CASCO (VEÍCULO)'\n",
    "                ).replace(\n",
    "                    'REPARAÇÃO OU REPOSIÇÃO DO (SEMI)REBOQUE', 'CASCO (R/SR)'\n",
    "                ).replace(\n",
    "                    'REPARAÇÃO OU REPOSIÇÃO DO COMPLEMENTO', 'CASCO (COMPLEMENTO)'\n",
    "                )\n",
    "            except Exception as e:\n",
    "                logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "                logging.info(f'Falha ao filtrar dados de cancelamentos referente ao dia anterior: {e}')\n",
    "\n",
    "            # Cancelamentos do dia anterior ou desde sexta\n",
    "            try:\n",
    "                df_cancelamentos['data_cancelamento'] = pd.to_datetime(df_cancelamentos['data_cancelamento']).dt.date\n",
    "                if today.weekday() == 0:\n",
    "                    df_cancelamentos = df_cancelamentos[df_cancelamentos['data_cancelamento'].between(friday, today)]\n",
    "                else:\n",
    "                    df_cancelamentos = df_cancelamentos[df_cancelamentos['data_cancelamento'] == yesterday]\n",
    "\n",
    "                df_cancelamentos = df_cancelamentos.sort_values(by='data_cancelamento', ascending=True)\n",
    "            except Exception as e:\n",
    "                logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "                logging.info(f'Falha ao filtrar dados de cancelamentos referente ao dia anterior: {e}')\n",
    "\n",
    "            # Ativações do dia anterior ou desde sexta\n",
    "            try:\n",
    "                if not df_ativacoes.empty:\n",
    "                    if today.weekday() != 0:\n",
    "                        df_ativacoes_menos_ontem = df_ativacoes.loc[\n",
    "                            ~(df_ativacoes['data_ativacao_beneficio'].isin([yesterday, today]))\n",
    "                        ]\n",
    "                        df_ativacoes_dia_anterior = df_ativacoes[df_ativacoes['data_ativacao_beneficio'] == yesterday]\n",
    "                    else:\n",
    "                        df_ativacoes_menos_ontem = df_ativacoes.loc[\n",
    "                            (df_ativacoes['data_ativacao_beneficio'] < friday)\n",
    "                        ]\n",
    "                        df_ativacoes_dia_anterior = df_ativacoes[\n",
    "                            df_ativacoes['data_ativacao_beneficio'].between(friday, yesterday)\n",
    "                        ]\n",
    "\n",
    "                    df_ativacoes_dia_anterior_tratado = self.board_status_treatment(\n",
    "                        df=df_ativacoes_dia_anterior, df_conf=df_conferencia\n",
    "                    )\n",
    "                    df_ativacoes_atualizado = pd.concat([df_ativacoes_menos_ontem, df_ativacoes_dia_anterior_tratado])\n",
    "\n",
    "                    logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "                    logging.info(f'Número de registros ativos na carteira tratado com os dados do dia anterior.')\n",
    "            except Exception as e:\n",
    "                logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "                logging.info(f'Falha ao incluir registros ativos referente ao dia anterior na contagem . Revise o código: {e}')\n",
    "\n",
    "            # Último tratamento do DataFrame de ativação\n",
    "            try:\n",
    "                df_final_ativacoes = df_ativacoes_atualizado[[\n",
    "                    'placa', 'chassi', 'id_placa', 'id_veiculo', 'id_carroceria', 'matricula', 'conjunto', 'unidade',\n",
    "                    'consultor', 'status_beneficio', 'cliente', 'data', 'data_ativacao_beneficio', 'suporte',\n",
    "                    'data_filtro', 'empresa', 'migration_from'\n",
    "                ]]\n",
    "                df_final_ativacoes = df_final_ativacoes.drop_duplicates(subset='chassi')\n",
    "\n",
    "                logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "                logging.info(f'Processo final de tratamento de dataframe de ativação realizado com sucesso!')\n",
    "            except Exception as e:\n",
    "                logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "                print(f'Falha ao tratar o dataframe de ativação: {e}')\n",
    "\n",
    "            # Tratando dados nulos nos DataFrames\n",
    "            try:\n",
    "                df_final_ativacoes['placa'] = df_final_ativacoes['placa'].fillna('SEM-PLACA')\n",
    "                df_final_ativacoes['chassi'] = df_final_ativacoes['chassi'].fillna('NULL')\n",
    "                df_final_ativacoes['id_placa'] = df_final_ativacoes['id_placa'].fillna(0)\n",
    "                df_final_ativacoes['id_veiculo'] = df_final_ativacoes['id_veiculo'].fillna(0)\n",
    "                df_final_ativacoes['id_carroceria'] = df_final_ativacoes['id_carroceria'].fillna(0)\n",
    "                df_final_ativacoes['matricula'] = df_final_ativacoes['matricula'].fillna(0)\n",
    "                df_final_ativacoes['conjunto'] = df_final_ativacoes['conjunto'].fillna(0)\n",
    "                df_final_ativacoes['unidade'] = df_final_ativacoes['unidade'].fillna('NULL')\n",
    "                df_final_ativacoes['consultor'] = df_final_ativacoes['consultor'].fillna('NULL')\n",
    "                df_final_ativacoes['status'] = df_final_ativacoes.get('status', pd.Series(['NULL']*len(df_final_ativacoes))).fillna('NULL')\n",
    "                df_final_ativacoes['cliente'] = df_final_ativacoes['cliente'].fillna('NULL')\n",
    "                df_final_ativacoes['data'] = df_final_ativacoes['data'].fillna(pd.Timestamp('1900-01-01'))\n",
    "                if 'data_ativacao' in df_final_ativacoes.columns:\n",
    "                    df_final_ativacoes['data_ativacao'] = df_final_ativacoes['data_ativacao'].fillna(pd.Timestamp('1900-01-01'))\n",
    "                df_final_ativacoes['suporte'] = df_final_ativacoes['suporte'].fillna('NULL')\n",
    "                df_final_ativacoes['data_filtro'] = df_final_ativacoes['data_filtro'].fillna(pd.Timestamp('1900-01-01'))\n",
    "                df_final_ativacoes['empresa'] = df_final_ativacoes['empresa'].fillna('NULL')\n",
    "\n",
    "                df_cancelamentos['placa'] = df_cancelamentos['placa'].fillna('SEM-PLACA')\n",
    "                df_cancelamentos['chassi'] = df_cancelamentos['chassi'].fillna('NULL')\n",
    "                df_cancelamentos['id_placa'] = df_cancelamentos['id_placa'].fillna(0)\n",
    "                df_cancelamentos['id_veiculo'] = df_cancelamentos['id_veiculo'].fillna(0)\n",
    "                df_cancelamentos['id_carroceria'] = df_cancelamentos['id_carroceria'].fillna(0)\n",
    "                df_cancelamentos['matricula'] = df_cancelamentos['matricula'].fillna(0)\n",
    "                df_cancelamentos['conjunto'] = df_cancelamentos['conjunto'].fillna(0)\n",
    "                df_cancelamentos['unidade'] = df_cancelamentos['unidade'].fillna('NULL')\n",
    "                df_cancelamentos['status'] = df_cancelamentos['status'].fillna('NULL')\n",
    "                df_cancelamentos['cliente'] = df_cancelamentos['cliente'].fillna('NULL')\n",
    "                df_cancelamentos['data'] = df_cancelamentos['data'].fillna(pd.Timestamp('1900-01-01'))\n",
    "                df_cancelamentos['data_cancelamento'] = df_cancelamentos['data_cancelamento'].fillna(pd.Timestamp('1900-01-01'))\n",
    "                df_cancelamentos['usuario_cancelamento'] = df_cancelamentos['usuario_cancelamento'].fillna('NULL')\n",
    "                df_cancelamentos['data_filtro'] = df_cancelamentos['data_filtro'].fillna(pd.Timestamp('1900-01-01'))\n",
    "                df_cancelamentos['empresa'] = df_cancelamentos['empresa'].fillna('NULL')\n",
    "\n",
    "                logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "                logging.info('\\n Processo de Transformacao de Dados concluido com sucesso!')\n",
    "            except Exception as e:\n",
    "                logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "                logging.info(f'Falha ao realizar tratamento de dados: {e}')\n",
    "        \n",
    "        except Exception as e:\n",
    "            logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "            logging.info(f'Falha ao realizar tratamento de dados: {e}')\n",
    "\n",
    "            # Retorno explícito das saídas, como nos métodos acima\n",
    "        \n",
    "        return df_final_ativacoes, df_cancelamentos\n",
    "\n",
    "        # Exemplo de como declarar as variáveis dos returns dos métodos para usar depois:\n",
    "        # Basta instanciar a classe e chamar os métodos, atribuindo o retorno a variáveis:\n",
    "try:\n",
    "    transform = Transform()\n",
    "except Exception as e:\n",
    "    logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "    logging.info(f'Falha ao instanciar a classe Transform: {e}')\n",
    "    raise\n",
    "df_final_ativacoes, df_final_cancelamentos = transform.transforming_files(df_ativacoes, df_cancelamentos, df_conferencia)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "34762361",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>placa</th>\n",
       "      <th>chassi</th>\n",
       "      <th>id_placa</th>\n",
       "      <th>id_veiculo</th>\n",
       "      <th>id_carroceria</th>\n",
       "      <th>matricula</th>\n",
       "      <th>conjunto</th>\n",
       "      <th>unidade</th>\n",
       "      <th>consultor</th>\n",
       "      <th>status_beneficio</th>\n",
       "      <th>cliente</th>\n",
       "      <th>data</th>\n",
       "      <th>data_ativacao_beneficio</th>\n",
       "      <th>suporte</th>\n",
       "      <th>data_filtro</th>\n",
       "      <th>empresa</th>\n",
       "      <th>migration_from</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7581</th>\n",
       "      <td>OOM9H35</td>\n",
       "      <td>98PTS47MSKB107595</td>\n",
       "      <td>1827</td>\n",
       "      <td>1827</td>\n",
       "      <td>0</td>\n",
       "      <td>472</td>\n",
       "      <td>500</td>\n",
       "      <td>UNIDADE CUIABA</td>\n",
       "      <td>Isabella Santos</td>\n",
       "      <td>ATIVO</td>\n",
       "      <td>MARCO BUS VIAGENS E TURISMO LTDA</td>\n",
       "      <td>2025-08-08</td>\n",
       "      <td>2025-08-08</td>\n",
       "      <td>Lucas Belmiro Mendes Santos</td>\n",
       "      <td>2025-08-20</td>\n",
       "      <td>Tag</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7585</th>\n",
       "      <td>AKV6G15</td>\n",
       "      <td>9AA07072G3C041923</td>\n",
       "      <td>2978</td>\n",
       "      <td>0</td>\n",
       "      <td>2978</td>\n",
       "      <td>2</td>\n",
       "      <td>733</td>\n",
       "      <td>UNIDADE CASCAVEL</td>\n",
       "      <td>Thiago Rosa De Figueiredo</td>\n",
       "      <td>ATIVO</td>\n",
       "      <td>JHONATH JORGE VOLTL</td>\n",
       "      <td>2025-08-13</td>\n",
       "      <td>2025-08-13</td>\n",
       "      <td>Andressa Silva de Oliveira Pinto</td>\n",
       "      <td>2025-08-20</td>\n",
       "      <td>Tag</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7586</th>\n",
       "      <td>AKV6F51</td>\n",
       "      <td>9AA07102G3C041922</td>\n",
       "      <td>2979</td>\n",
       "      <td>0</td>\n",
       "      <td>2979</td>\n",
       "      <td>2</td>\n",
       "      <td>733</td>\n",
       "      <td>UNIDADE CASCAVEL</td>\n",
       "      <td>Thiago Rosa De Figueiredo</td>\n",
       "      <td>ATIVO</td>\n",
       "      <td>JHONATH JORGE VOLTL</td>\n",
       "      <td>2025-08-13</td>\n",
       "      <td>2025-08-13</td>\n",
       "      <td>Andressa Silva de Oliveira Pinto</td>\n",
       "      <td>2025-08-20</td>\n",
       "      <td>Tag</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7587</th>\n",
       "      <td>SDT3C95</td>\n",
       "      <td>9BVRG40D6NE923631</td>\n",
       "      <td>100173</td>\n",
       "      <td>100173</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>733</td>\n",
       "      <td>UNIDADE CASCAVEL</td>\n",
       "      <td>Thiago Rosa De Figueiredo</td>\n",
       "      <td>ATIVO</td>\n",
       "      <td>JHONATH JORGE VOLTL</td>\n",
       "      <td>2025-08-13</td>\n",
       "      <td>2025-08-13</td>\n",
       "      <td>Andressa Silva de Oliveira Pinto</td>\n",
       "      <td>2025-08-20</td>\n",
       "      <td>Tag</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7589</th>\n",
       "      <td>IKK6B94</td>\n",
       "      <td>9EP07052021000078</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>UNIDADE CASCAVEL</td>\n",
       "      <td>Thiago Rosa De Figueiredo</td>\n",
       "      <td>ATIVO</td>\n",
       "      <td>JHONATH JORGE VOLTL</td>\n",
       "      <td>2025-08-01</td>\n",
       "      <td>2025-08-06</td>\n",
       "      <td>Lucas Belmiro Mendes Santos</td>\n",
       "      <td>2025-08-20</td>\n",
       "      <td>Tag</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        placa             chassi  id_placa  id_veiculo  id_carroceria  \\\n",
       "7581  OOM9H35  98PTS47MSKB107595      1827        1827              0   \n",
       "7585  AKV6G15  9AA07072G3C041923      2978           0           2978   \n",
       "7586  AKV6F51  9AA07102G3C041922      2979           0           2979   \n",
       "7587  SDT3C95  9BVRG40D6NE923631    100173      100173              0   \n",
       "7589  IKK6B94  9EP07052021000078        15           0             15   \n",
       "\n",
       "      matricula  conjunto           unidade                  consultor  \\\n",
       "7581        472       500    UNIDADE CUIABA            Isabella Santos   \n",
       "7585          2       733  UNIDADE CASCAVEL  Thiago Rosa De Figueiredo   \n",
       "7586          2       733  UNIDADE CASCAVEL  Thiago Rosa De Figueiredo   \n",
       "7587          2       733  UNIDADE CASCAVEL  Thiago Rosa De Figueiredo   \n",
       "7589          2         4  UNIDADE CASCAVEL  Thiago Rosa De Figueiredo   \n",
       "\n",
       "     status_beneficio                           cliente       data  \\\n",
       "7581            ATIVO  MARCO BUS VIAGENS E TURISMO LTDA 2025-08-08   \n",
       "7585            ATIVO               JHONATH JORGE VOLTL 2025-08-13   \n",
       "7586            ATIVO               JHONATH JORGE VOLTL 2025-08-13   \n",
       "7587            ATIVO               JHONATH JORGE VOLTL 2025-08-13   \n",
       "7589            ATIVO               JHONATH JORGE VOLTL 2025-08-01   \n",
       "\n",
       "     data_ativacao_beneficio                            suporte data_filtro  \\\n",
       "7581              2025-08-08        Lucas Belmiro Mendes Santos  2025-08-20   \n",
       "7585              2025-08-13  Andressa Silva de Oliveira Pinto   2025-08-20   \n",
       "7586              2025-08-13  Andressa Silva de Oliveira Pinto   2025-08-20   \n",
       "7587              2025-08-13  Andressa Silva de Oliveira Pinto   2025-08-20   \n",
       "7589              2025-08-06        Lucas Belmiro Mendes Santos  2025-08-20   \n",
       "\n",
       "     empresa migration_from status  \n",
       "7581     Tag            NaN   NULL  \n",
       "7585     Tag            NaN   NULL  \n",
       "7586     Tag            NaN   NULL  \n",
       "7587     Tag            NaN   NULL  \n",
       "7589     Tag            NaN   NULL  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final_ativacoes[df_final_ativacoes['empresa'] =='Tag'].head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
