{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf422456",
   "metadata": {},
   "source": [
    "# EXTRACT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54790159",
   "metadata": {},
   "outputs": [],
   "source": [
    "import awswrangler as awr\n",
    "import logging\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,  # Exibe mensagens a partir de INFO\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "    handlers=[\n",
    "        logging.StreamHandler()  # Garante logs no console\n",
    "    ]\n",
    ")\n",
    "\n",
    "logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "logging.info('\\n Executando Rotina - RELATORIO ATIVACOES PENDENTES')\n",
    "\n",
    "class Extract:\n",
    "\n",
    "    # FUNÇÃO CONSTRUTORA\n",
    "    def __init__(self):\n",
    "        #self.path = os.path.dirname(__file__) #atributo de instância que obtém o caminho do diretório dirname\n",
    "        self.path = r\"C:\\Users\\raphael.almeida\\Documents\\Processos\\placas_acompanhamento\"\n",
    "\n",
    "    # FUNÇÃO PARA EXTRAÇÃO DE DADOS DE: ATIVAÇÕES\n",
    "    def extract_all_ativacoes(self):\n",
    "        \"\"\"\n",
    "        Retorna um DataFrame com os dados de ativações.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            dir_query = os.path.join(self.path, 'sql', 'all_boards_ATIVOS.sql')\n",
    "            with open(dir_query, 'r') as file:\n",
    "                query = file.read()\n",
    "            df_ativacoes = awr.athena.read_sql_query(query, database='silver')\n",
    "            logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "            logging.info('\\n Relatorio ativacoes (Vivante)  - Dados Extraidos com sucesso!')\n",
    "            return df_ativacoes\n",
    "        except Exception as e:\n",
    "            logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "            logging.info(f'\\n Falha ao Extrair relatorio ativacoes (Viavante): {e}')\n",
    "            return None\n",
    "\n",
    "    # FUNÇÃO PARA EXTRAÇÃO DE DADOS DE: CANCELAMENTO INTEGRAL\n",
    "    def extract_all_cancelamentos(self):\n",
    "        \"\"\"\n",
    "        Retorna um DataFrame com os dados de cancelamentos.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            dir_query = os.path.join(self.path, 'sql', 'all_boards_CANCELADOS.sql')\n",
    "            with open(dir_query, 'r') as file:\n",
    "                query = file.read()\n",
    "            df_cancelamentos = awr.athena.read_sql_query(query, database='silver')\n",
    "            logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "            logging.info('\\n Relatorio cancelamentos  - Dados Extraidos com sucesso!')\n",
    "            return df_cancelamentos\n",
    "        except Exception as e:\n",
    "            logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "            logging.info(f'\\n Falha ao Extrair relatorio cancelamentos: {e}')\n",
    "            return None\n",
    "\n",
    "    # FUNÇÃO PARA EXTRAÇÃO DE DADOS DE: CONFERÊNCIA\n",
    "    def extract_conf_boards(self):\n",
    "        \"\"\"\n",
    "        Retorna um DataFrame com os dados de conferência.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            dir_query = os.path.join(self.path, 'sql', 'listagem_mestra.sql')\n",
    "            with open(dir_query, 'r') as file:\n",
    "                query = file.read()\n",
    "            df_conferencia = awr.athena.read_sql_query(query, database='silver')\n",
    "            logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "            logging.info('\\n Relatorio conferência  - Dados Extraidos com sucesso!')\n",
    "            return df_conferencia\n",
    "        except Exception as e:\n",
    "            logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "            logging.info(f'\\n Falha ao Extrair relatorio conferência: {e}')\n",
    "            return None\n",
    "\n",
    "# Exemplo de como declarar as variáveis dos returns dos métodos para usar depois:\n",
    "# Basta instanciar a classe e chamar os métodos, atribuindo o retorno a variáveis:\n",
    "\n",
    "extract = Extract()\n",
    "df_ativacoes = extract.extract_all_ativacoes()\n",
    "df_cancelamentos = extract.extract_all_cancelamentos()\n",
    "df_conferencia = extract.extract_conf_boards()\n",
    "\n",
    "# Agora você pode usar df_ativacoes, df_cancelamentos, df_conferencia normalmente no seu código.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839be64a",
   "metadata": {},
   "source": [
    "# TRANSFORM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93b6069b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\raphael.almeida\\AppData\\Local\\Temp\\ipykernel_24300\\2422733778.py:41: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'NULL' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[idx, 'migration_from'] = 'NULL'\n",
      "C:\\Users\\raphael.almeida\\AppData\\Local\\Temp\\ipykernel_24300\\2422733778.py:41: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'NULL' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[idx, 'migration_from'] = 'NULL'\n",
      "C:\\Users\\raphael.almeida\\AppData\\Local\\Temp\\ipykernel_24300\\2422733778.py:41: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'NULL' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[idx, 'migration_from'] = 'NULL'\n",
      "C:\\Users\\raphael.almeida\\AppData\\Local\\Temp\\ipykernel_24300\\2422733778.py:63: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'NULL' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[idx, 'migration_from'] = 'NULL'\n"
     ]
    }
   ],
   "source": [
    "# IMPORTANDO MÓDULOS E PACOTES\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import logging\n",
    "import traceback\n",
    "import numpy as np\n",
    "\n",
    "class Transform:\n",
    "        \n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "\n",
    "    # CRIANDO FUNÇÃO QUE IRÁ APLICAR O TRATAMENTO DE STATUS DAS PLACAS ATIVADAS\n",
    "    def board_status_treatment(df, df_conf,status_filter_list):\n",
    "\n",
    "        try:\n",
    "            if not df.empty:\n",
    "                logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "                logging.info(df.shape)\n",
    "                row_count = 0\n",
    "                for idx, row in df.iterrows():\n",
    "                    row_count += 1\n",
    "                    df_verification = df_conf[\n",
    "                        (df_conf['chassi'] == row['chassi']) & (df_conf['beneficio'] == row['beneficio'])\n",
    "                    ].sort_values(by='data_ativacao', ascending=True)\n",
    "\n",
    "                    if not df_verification.empty and len(df_verification['empresa'].values) > 1:\n",
    "                        hist_datas_ativacao = sorted(df_verification['data_ativacao_beneficio'].dropna().drop_duplicates().unique())\n",
    "\n",
    "                        if len(hist_datas_ativacao) > 1:\n",
    "                            penultimo_registro_data = hist_datas_ativacao[-2]\n",
    "                            verification_penultima_row = df_verification.loc[df_verification['data_ativacao_beneficio'] == penultimo_registro_data]\n",
    "                            \n",
    "                            if verification_penultima_row['status_beneficio'].values[0] not in status_filter_list:\n",
    "                                if verification_penultima_row['empresa'].values[0] != row['empresa']:\n",
    "                                    df.at[idx, 'status_beneficio'] = 'MIGRAÇÃO'\n",
    "                                    df.at[idx, 'migration_from'] = verification_penultima_row['empresa'].values[0]\n",
    "                                else:\n",
    "                                    df.at[idx, 'status_beneficio'] = 'RENOVAÇÃO'\n",
    "                                    df.at[idx, 'migration_from'] = 'NULL'\n",
    "                            else:\n",
    "                                # today = dt.datetime.today()\n",
    "                                # hist_datas_atualizacao = sorted(df_verification['data_atualizacao'].dropna().drop_duplicates().unique())\n",
    "                                # penultimo_registro_data_atualizacao = hist_datas_atualizacao[-2]\n",
    "                                # if today - penultimo_registro_data_atualizacao > dt.timedelta(days=30):\n",
    "                                    df.at[idx, 'status_beneficio'] = 'REATIVAÇÃO'\n",
    "                                    df.at[idx, 'migration_from'] = 'NULL'\n",
    "                                    \n",
    "                                # else:\n",
    "                                #     if verification_penultima_row ['empresa'].values[0] != row['empresa']:\n",
    "                                #         df.at[idx, 'status_beneficio'] = 'MIGRAÇÃO'\n",
    "                                #         df.at[idx, 'migration_from'] = verification_penultima_row['empresa'].values[0]\n",
    "                                #     else:\n",
    "                                #         df.at[idx, 'status_beneficio'] = 'RENOVAÇÃO'\n",
    "                                #         df.at[idx, 'migration_from'] = 'NULL'\n",
    "                                    \n",
    "                        else:\n",
    "                            df.at[idx, 'status_beneficio'] = 'NOVO'\n",
    "                            df.at[idx, 'migration_from'] = 'NULL'\n",
    "                    else:\n",
    "                        df.at[idx, 'status_beneficio'] = 'NOVO'\n",
    "                        df.at[idx, 'migration_from'] = 'NULL'\n",
    "\n",
    "                logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "                logging.info(f'Total de linhas processadas: {row_count}')\n",
    "\n",
    "            else:\n",
    "                logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "                logging.info('Nnehum registro de ativações para tratamento de dados. Dataframe vazio!')\n",
    "\n",
    "\n",
    "        except Exception as e:\n",
    "\n",
    "            logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "            logging.info(f'Falha no tratamento de status das placas ativadas. Revise o código: {e}')\n",
    "\n",
    "        return df\n",
    "    \n",
    "\n",
    "    # FUNÇÃO PARA DECODIFICAR A COLUNA 'RENEGOCIACAO'\n",
    "    def decode_renegociacao(value):\n",
    "        if value == 14326:\n",
    "            return 'NAO'\n",
    "        elif value == 14324:\n",
    "            return 'SIM'\n",
    "        elif value == 0:\n",
    "            return 'VAZIO'\n",
    "        else:\n",
    "            logging.info('Código não encontrado para decodificação na coluna \"Renegociacao\". Revise o código:')\n",
    "            logging.info(value)\n",
    "            return value\n",
    "\n",
    "    # FUNÇÃO PARA DECODIFICAR A COLUNA 'EMPRESA'\n",
    "    def decode_empresa(value):\n",
    "\n",
    "        if value == 4330:\n",
    "            return 'Viavante'\n",
    "        elif value == 4328:\n",
    "            return 'Stcoop'\n",
    "        elif value == 4326:\n",
    "            return 'Segtruck'\n",
    "        elif value == 0:\n",
    "            return 'Sem Empresa' \n",
    "        else:\n",
    "            logging.info('Código não encontrado para decodificação na coluna \"Empresa\". Revise o código:')\n",
    "            logging.info(value)\n",
    "            return value\n",
    "    \n",
    "\n",
    "    # FUNÇÃO PARA DESMENBRAR OS CONJUNTOS\n",
    "    def correcao_valores_conjunto(value):\n",
    "\n",
    "        if pd.isna(value):\n",
    "            return []\n",
    "        \n",
    "        for sep in ['e', '/', '-', ' ']:\n",
    "            value = value.replace(sep, ',')\n",
    "\n",
    "        value = str(value).lower().strip()\n",
    "\n",
    "        value = value.replace(',,', ',')\n",
    "\n",
    "        value = value.replace('.', '')\n",
    "\n",
    "        elementos = [v for v in value.split(',') if v.strip() != '']\n",
    "\n",
    "        try:\n",
    "            formated_value = [int(v) for v in elementos]\n",
    "        except ValueError:\n",
    "            formated_value = elementos  \n",
    "\n",
    "        return formated_value\n",
    "\n",
    "\n",
    "    # CRIANDO FUNÇÃO QUE IRÁ REALIZAR A TRANSFORMAÇÃO E TRATAMENTO DOS DADOS PARA A CAMPANHA\n",
    "    def transforming_files(self):\n",
    "\n",
    "        try:\n",
    "\n",
    "            # INICIALIANDO DATAFRAMES VAZIOS\n",
    "            df_final_ativacoes = pd.DataFrame()\n",
    "            df_final_cancelamentos = pd.DataFrame()\n",
    "\n",
    "\n",
    "            # DEFININDO DATA DE INICIO DA CAMPANHA E CRIANDO DATAFRAME COM TODAS AS DATAS DE CAMPANHA\n",
    "            today = dt.date.today()\n",
    "            yesterday = today - dt.timedelta(days=1)\n",
    "            last_friday = today - dt.timedelta(days=3)\n",
    "            comeco_campanha = dt.date(2025, 5, 1)\n",
    "            lista_dias_faltantes = [dt.date(2025,7,20), dt.date(2025,7,28), dt.date(2025,7,29), \n",
    "            dt.date(2025,7,30), dt.date(2025,7,31)]\n",
    "            date_for_all = pd.date_range(start=comeco_campanha, end=today, freq='D')\n",
    "\n",
    "        except Exception as e:\n",
    "\n",
    "            logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "            logging.info('Falha ao criar parâmetros de data para filtragem de dataframes.')\n",
    "\n",
    "        # EXTRAINDO DATAFRAMES E SEGMENTANDO-OS POR EMPRESA / PADRONIZANDO BENEFICIOS\n",
    "        try:\n",
    "            extract_inst = Extract()\n",
    "            df_final_cancelamentos = extract_inst.extract_all_cancelamentos()\n",
    "            \n",
    "        \n",
    "            df_ativ_all_boards = extract_inst.extract_all_ativacoes()\n",
    "            df_ativ_all_boards['data_ativacao_beneficio'] = pd.to_datetime(df_ativ_all_boards['data_ativacao_beneficio']).dt.date\n",
    "                        \n",
    "            df_ativ_all_boards['beneficio'] = df_ativ_all_boards['beneficio'].replace('REPARAÇÃO OU REPOSIÇÃO DO VEÍCULO', 'CASCO (VEÍCULO)').replace('REPARAÇÃO OU REPOSIÇÃO DO (SEMI)REBOQUE', 'CASCO (R/SR)').replace('REPARAÇÃO OU REPOSIÇÃO DO COMPLEMENTO', 'CASCO (COMPLEMENTO)')\n",
    "            \n",
    "            df_ativ_viavante = df_ativ_all_boards[df_ativ_all_boards['empresa'] == 'Viavante']\n",
    "            df_ativ_stcoop = df_ativ_all_boards[df_ativ_all_boards['empresa'] == 'Stcoop']\n",
    "            df_ativ_segtruck = df_ativ_all_boards[df_ativ_all_boards['empresa'] == 'Segtruck']\n",
    "            df_ativ_tag = df_ativ_all_boards[df_ativ_all_boards['empresa'] == 'Tag']\n",
    "\n",
    "            df_conf_all_boards = extract_inst.extract_conf_boards()\n",
    "            df_conf_all_boards['beneficio'] = df_conf_all_boards['beneficio'].replace('REPARAÇÃO OU REPOSIÇÃO DO VEÍCULO', 'CASCO (VEÍCULO)').replace('REPARAÇÃO OU REPOSIÇÃO DO (SEMI)REBOQUE', 'CASCO (R/SR)').replace('REPARAÇÃO OU REPOSIÇÃO DO COMPLEMENTO', 'CASCO (COMPLEMENTO)')\n",
    "\n",
    "        except Exception as e:\n",
    "\n",
    "            logging.info('\\n ----------------------------------------------------------------------------------')  \n",
    "            logging.info(f'Falha ao realizar a segmentação dos dataframes: {e}')\n",
    "\n",
    "\n",
    "\n",
    "        # SELECIONANDO APENAS AS ATIVAÇÕES CORRESPONDENTES AOS BENEFICIOS 'CASCO' / 'TERCEIRO' POR UM REGEX PADRÃO\n",
    "        try:\n",
    "\n",
    "            ids_beneficios_segtruck = [2, 3, 4, 7, 24, 25, 26, 29]\n",
    "            ids_beneficios_stcoop = [24, 25, 26, 29]\n",
    "            ids_beneficios_viavante = [40, 41, 42, 45]\n",
    "            ids_beneficios_tag = [2, 3, 4, 7, 24, 25, 26, 29, 34, 35, 36, 37, 38, 39]\n",
    "\n",
    "            df_ativ_viavante = df_ativ_viavante.loc[df_ativ_viavante['id_beneficio'].isin(ids_beneficios_viavante)]\n",
    "            df_ativ_stcoop = df_ativ_stcoop[df_ativ_stcoop['id_beneficio'].isin(ids_beneficios_stcoop)]\n",
    "            df_ativ_segtruck = df_ativ_segtruck.loc[df_ativ_segtruck['id_beneficio'].isin(ids_beneficios_segtruck)]\n",
    "            df_ativ_tag = df_ativ_tag.loc[df_ativ_tag['id_beneficio'].isin(ids_beneficios_tag)]\n",
    "\n",
    "        except Exception as e:\n",
    "\n",
    "            logging.info('\\n ----------------------------------------------------------------------------------')  \n",
    "            logging.info(f'Falha ao padronizar nomenclaturas referente aos beneficios pré-estabelecidos: {e}')\n",
    "\n",
    "\n",
    "        # FILTRANDO OS DADOS PELA DATA DE CANCELAMENTO / DATA DE ATUALIZAÇÃO, E ORDENANDO OS DADOS NO DATAFRAME PELAS COLUNAS DE DATA\n",
    "        try:\n",
    "\n",
    "            # IDENTIFICANDO CANCELAMENTOS POR MIGRAÇÃO\n",
    "            #df_final_cancelamentos_integrais = pd.merge(df_final_cancelamentos, df_cancelamentos_dia_anterior_bitrix, on=['conjunto', 'empresa', 'data_cancelamento'], how='left')\n",
    "            #df_final_cancelamentos.drop(columns=['ID'], inplace=True)\n",
    "            df_final_cancelamentos_integrais = df_final_cancelamentos\n",
    "            # FILTRANDO DADOS DE CANCELAMENTOS INTEGRAIS\n",
    "            #df_final_cancelamentos_integrais['data_cancelamento'] = pd.to_datetime(df_final_cancelamentos_integrais['data_cancelamento']).dt.date\n",
    "            #df_final_cancelamentos_integrais['data_substituicao'] = pd.to_datetime(df_final_cancelamentos_integrais['data_substituicao']).dt.date\n",
    "            #if today.weekday() == 0:\n",
    "            #    df_final_cancelamentos_integrais = df_final_cancelamentos_integrais[\n",
    "            #        (df_final_cancelamentos_integrais['data_cancelamento'].between(last_friday, today)) |\n",
    "            #        (df_final_cancelamentos_integrais['data_substituicao'].between(last_friday, today))]\n",
    "            #else:\n",
    "            #    df_final_cancelamentos_integrais = df_final_cancelamentos_integrais[\n",
    "            #        (df_final_cancelamentos_integrais['data_cancelamento'] == yesterday) |\n",
    "            #        (df_final_cancelamentos_integrais['data_substituicao'] == yesterday)]\n",
    "                \n",
    "            # REORDENANDO AS COLUNAS DA BASE DE CANCELAMENTOS INTEGRAIS\n",
    "            #df_final_cancelamentos_integrais = df_final_cancelamentos_integrais[['placa', 'chassi', 'id_placa', 'id_veiculo', 'id_carroceria', 'conjunto', 'unidade', 'status', 'cliente', 'data_registro', 'data_cancelamento', 'suporte', 'data_extracao', 'empresa', 'data_registro_historico', 'migracao', 'renegociacao', 'data_substituicao']]\n",
    "            #df_final_cancelamentos_integrais = df_final_cancelamentos_integrais.sort_values(by=['data_cancelamento', 'data_substituicao'], ascending=True)\n",
    "\n",
    "            \n",
    "        except Exception as e:\n",
    "\n",
    "            logging.info('\\n ----------------------------------------------------------------------------------')  \n",
    "            logging.info(f'Falha ao filtrar dados de cancelamentos referente ao dia anterior: {e}')\n",
    "\n",
    "        # CRIANDO COLUNA DE MIGRAÇÃO (MIGRATION_FROM) E DEFININDO FILTRO DE STATUS PARA TRATAMENTO DE DADOS DA CAMPANHA\n",
    "        try:\n",
    "            if not df_ativ_tag.empty:\n",
    "                df_ativ_tag['migration_from'] = np.nan\n",
    "            if not df_ativ_viavante.empty:\n",
    "                df_ativ_viavante['migration_from'] = np.nan\n",
    "            if not df_ativ_stcoop.empty:\n",
    "                df_ativ_stcoop['migration_from'] = np.nan\n",
    "            if not df_ativ_segtruck.empty:\n",
    "                df_ativ_segtruck['migration_from'] = np.nan\n",
    "            if not df_ativ_all_boards.empty:\n",
    "                df_ativ_all_boards['migration_from'] = np.nan\n",
    "\n",
    "            # CRIANDO LISTA DE VERIFICAÇÃOST DE PLACAS MIGRADAS (STATUS)\n",
    "            status_filter_list = ['CANCELADO', 'CANCELADA', 'FINALIZADO', 'FINALIZADA', 'NAO RENOVADO']\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "            logging.info(f'Falha na ciração das colunas de migração e definição de filtro de status: {e}')\n",
    "\n",
    "\n",
    "        # GERANDO DATAFRAME FINAL (TAG)\n",
    "        '''\n",
    "            AQUI SÃO FILTRADOS OS DADOS PELA DATA DE ATIVAÇÃO DO BENEFICIO, CASO A DATA SEJA UMA SEGUNDA-FEIRA ELE RETORNA OS DADOS DA SEXTA-FEIRA ANTERIOR ATÉ A SEGUNDA-FEIRA\n",
    "            CASO CONTRÁRIO, ELE RETORNA OS DADOS DO DIA ANTERIOR.\n",
    "        '''\n",
    "        try:\n",
    "            \n",
    "            if not df_ativ_tag.empty:\n",
    "                if today.weekday() == 0:\n",
    "                    df_final_tg = df_ativ_tag[df_ativ_tag['data_ativacao_beneficio'].between(last_friday, today)]\n",
    "                else:\n",
    "                    df_final_tg = df_ativ_tag[df_ativ_tag['data_ativacao_beneficio'] == yesterday]\n",
    "            else:\n",
    "                df_final_tg = pd.DataFrame()\n",
    "                logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "                logging.info(f'Nenhum registro de ativação encontrado na Viavante')\n",
    "\n",
    "        except Exception as e:\n",
    "\n",
    "            logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "            logging.info(f'Falha ao atualizar placas referente a Viavante: {e}')\n",
    "\n",
    "\n",
    "        # GERANDO DATAFRAME FINAL (VIAVANTE)\n",
    "        '''\n",
    "            AQUI SÃO FILTRADOS OS DADOS PELA DATA DE ATIVAÇÃO DO BENEFICIO, CASO A DATA SEJA UMA SEGUNDA-FEIRA ELE RETORNA OS DADOS DA SEXTA-FEIRA ANTERIOR ATÉ A SEGUNDA-FEIRA\n",
    "            CASO CONTRÁRIO, ELE RETORNA OS DADOS DO DIA ANTERIOR.\n",
    "        '''\n",
    "        try:\n",
    "            \n",
    "            if not df_ativ_viavante.empty:\n",
    "                if today.weekday() == 0:\n",
    "                    df_final_viav = df_ativ_viavante[df_ativ_viavante['data_ativacao_beneficio'].between(last_friday, today)]\n",
    "                else:\n",
    "                    df_final_viav = df_ativ_viavante[df_ativ_viavante['data_ativacao_beneficio'] == yesterday]\n",
    "            else:\n",
    "                df_final_viav = pd.DataFrame()\n",
    "                logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "                logging.info(f'Nenhum registro de ativação encontrado na Viavante')\n",
    "\n",
    "        except Exception as e:\n",
    "\n",
    "            logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "            logging.info(f'Falha ao atualizar placas referente a Viavante: {e}')\n",
    "\n",
    "\n",
    "        # GERANDO DATAFRAME FINAL (STCOOP)\n",
    "        '''\n",
    "            AQUI SÃO FILTRADOS OS DADOS PELA DATA DE ATIVAÇÃO DO BENEFICIO, CASO A DATA SEJA UMA SEGUNDA-FEIRA ELE RETORNA OS DADOS DA SEXTA-FEIRA ANTERIOR ATÉ A SEGUNDA-FEIRA\n",
    "            CASO CONTRÁRIO, ELE RETORNA OS DADOS DO DIA ANTERIOR.\n",
    "        '''\n",
    "        try:\n",
    "            if not df_ativ_stcoop.empty:\n",
    "                if today.weekday() == 0:\n",
    "                    df_final_st = df_ativ_stcoop[df_ativ_stcoop['data_ativacao_beneficio'].between(last_friday, today)]\n",
    "                else:\n",
    "                    df_final_st = df_ativ_stcoop[df_ativ_stcoop['data_ativacao_beneficio'] == yesterday]\n",
    "            else:\n",
    "                df_final_st = pd.DataFrame()\n",
    "                logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "                logging.info(f'Nenhum registro de ativação encontrado na Stcoop')\n",
    "\n",
    "        except Exception as e:\n",
    "\n",
    "            logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "            logging.info(f'Falha ao atualizar as ativações referente a Stcoop: {e}')\n",
    "\n",
    "        # GERANDO DATAFRAME FINAL (Segtruck)\n",
    "        '''\n",
    "            AQUI SÃO FILTRADOS OS DADOS PELA DATA DE ATIVAÇÃO DO BENEFICIO, CASO A DATA SEJA UMA SEGUNDA-FEIRA ELE RETORNA OS DADOS DA SEXTA-FEIRA ANTERIOR ATÉ A SEGUNDA-FEIRA\n",
    "            CASO CONTRÁRIO, ELE RETORNA OS DADOS DO DIA ANTERIOR.\n",
    "        '''\n",
    "        try:\n",
    "            if not df_ativ_segtruck.empty:\n",
    "                if today.weekday() == 0:\n",
    "                    df_final_seg = df_ativ_segtruck[df_ativ_segtruck['data_ativacao_beneficio'].between(last_friday, today)]\n",
    "                else:\n",
    "                    df_final_seg = df_ativ_segtruck[df_ativ_segtruck['data_ativacao_beneficio'] == yesterday]\n",
    "            else:\n",
    "                df_final_seg = pd.DataFrame()\n",
    "                logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "                logging.info(f'Nenhum registro de ativação encontrado na Segtruck')\n",
    "\n",
    "        except Exception as e:\n",
    "\n",
    "            logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "            logging.info(f'Falha ao atualizar as ativações referente a Segtruck: {e}')\n",
    "\n",
    "\n",
    "        try:\n",
    "            # PEGANDO DADOS DE ATIVAÇÃO DO DIA ANTERIOR\n",
    "            if not df_ativ_all_boards.empty:\n",
    "                df_ativos_menos_ontem = df_ativ_all_boards[~(df_ativ_all_boards['data_ativacao_beneficio'] == yesterday)]\n",
    "                df_ativos_dia_anterior = df_ativ_all_boards[df_ativ_all_boards['data_ativacao_beneficio'] == yesterday]\n",
    "                df_ativacoes_dia_anterior_ranking_tratado = Transform.board_status_treatment(df=df_ativos_dia_anterior, df_conf=df_conf_all_boards, status_filter_list=status_filter_list)\n",
    "                df_ativacoes_atualizado = pd.concat([df_ativos_menos_ontem, df_ativacoes_dia_anterior_ranking_tratado])\n",
    "                \n",
    "                logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "                logging.info(f'Número de registros ativos na carteira tratado com os dados do dia anterior.')\n",
    "\n",
    "        except Exception as e:\n",
    "\n",
    "            logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "            logging.info(f'Falha ao incluir registros ativos referente ao dia anterior na contagem . Revise o código: {e}')\n",
    "\n",
    "\n",
    "        # CRIANDO DATAFRAMES FINAIS: ATIVAÇÕES E CANCELAMENTOS\n",
    "        try:\n",
    "            # APLICANDO FUNÇÃO DE TRATAMENTO DE STATUS DAS PLACAS ATIVADAS\n",
    "            df_final_viavante = Transform.board_status_treatment(df=df_final_viav, df_conf=df_conf_all_boards, status_filter_list=status_filter_list)\n",
    "            df_final_stcoop = Transform.board_status_treatment(df=df_final_st, df_conf=df_conf_all_boards, status_filter_list=status_filter_list)\n",
    "            df_final_segtruck = Transform.board_status_treatment(df=df_final_seg, df_conf=df_conf_all_boards, status_filter_list=status_filter_list)\n",
    "            df_final_tag = Transform.board_status_treatment(df=df_final_tg, df_conf=df_conf_all_boards, status_filter_list=status_filter_list)\n",
    "\n",
    "            # CONCATENANDO DATAFRAMES DE ATIVAÇÕES DA CAMPANHA\n",
    "            df_ativacoes_dia_anterior_ranking = pd.concat([df_final_viavante, df_final_stcoop, df_final_segtruck, df_final_tag])\n",
    "            df_ativacoes_dia_anterior_ranking = df_ativacoes_dia_anterior_ranking.sort_values(by='data_ativacao_beneficio', ascending=True)\n",
    "            \n",
    "\n",
    "            # DEFININDO COLUNAS QUE SERÃO UTILIZADAS NOS DATAFRAMES FINAIS\n",
    "\n",
    "            df_final_ativacoes = df_ativacoes_atualizado[[\n",
    "                'placa', 'chassi', 'id_placa', 'id_veiculo', 'id_carroceria', 'matricula', 'conjunto', 'unidade', 'consultor', 'status_beneficio', \n",
    "                'cliente', 'data_registro', 'data_ativacao_beneficio', 'suporte', 'data_filtro', 'empresa', 'migration_from'\n",
    "            ]]\n",
    "\n",
    "            logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "            logging.info(f'Processo de Concatenação de Dataframes realizado com sucesso!')\n",
    "\n",
    "        except Exception as e:\n",
    "\n",
    "            logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "            logging.info(f'Falha ao unir os dataframes: {e}')\n",
    "\n",
    "        # TRATANDO NÚMERO DE REGISTROS ATIVOS / RETIRANDO DUPLICATAS\n",
    "        try:\n",
    "            df_final_ativacoes = df_final_ativacoes.drop_duplicates(subset='chassi')\n",
    "\n",
    "            logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "            logging.info(f'Número de registros ativos tratado e corrigido com sucesso.')\n",
    "\n",
    "        except Exception as e:\n",
    "\n",
    "            logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "            logging.info(f'Falha ao tratar e corrigir número de registros ativos. Revise o código: {e}')\n",
    "\n",
    "        # TRATANDO DADOS NULOS NOS DATAFRAMES\n",
    "        try:\n",
    "            df_final_ativacoes['placa'] = df_final_ativacoes['placa'].fillna('SEM-PLACA')\n",
    "            df_final_ativacoes['chassi'] = df_final_ativacoes['chassi'].fillna('NULL')\n",
    "            df_final_ativacoes['id_placa'] = df_final_ativacoes['id_placa'].fillna(0)\n",
    "            df_final_ativacoes['id_veiculo'] = df_final_ativacoes['id_veiculo'].fillna(0)\n",
    "            df_final_ativacoes['id_carroceria'] = df_final_ativacoes['id_carroceria'].fillna(0)\n",
    "            df_final_ativacoes['matricula'] = df_final_ativacoes['matricula'].fillna(0)\n",
    "            df_final_ativacoes['conjunto'] = df_final_ativacoes['conjunto'].fillna(0)\n",
    "            df_final_ativacoes['unidade'] = df_final_ativacoes['unidade'].fillna('NULL')\n",
    "            df_final_ativacoes['consultor'] = df_final_ativacoes['consultor'].fillna('NULL')\n",
    "            df_final_ativacoes['status_beneficio'] = df_final_ativacoes['status_beneficio'].fillna('NULL')\n",
    "            df_final_ativacoes['cliente'] = df_final_ativacoes['cliente'].fillna('NULL')\n",
    "            df_final_ativacoes['data_registro'] = df_final_ativacoes['data_registro'].fillna(pd.Timestamp('1900-01-01'))\n",
    "            df_final_ativacoes['data_ativacao_beneficio'] = df_final_ativacoes['data_ativacao_beneficio'].fillna(pd.Timestamp('1900-01-01'))\n",
    "            df_final_ativacoes['suporte'] = df_final_ativacoes['suporte'].fillna('NULL')\n",
    "            df_final_ativacoes['data_filtro'] = df_final_ativacoes['data_filtro'].fillna(pd.Timestamp('1900-01-01'))\n",
    "            df_final_ativacoes['empresa'] = df_final_ativacoes['empresa'].fillna('NULL')\n",
    "            df_final_ativacoes['migration_from'] = df_final_ativacoes['migration_from'].fillna('NULL')\n",
    "\n",
    "            df_final_cancelamentos_integrais['placa'] = df_final_cancelamentos_integrais['placa'].fillna('SEM-PLACA')\n",
    "            df_final_cancelamentos_integrais['chassi'] = df_final_cancelamentos_integrais['chassi'].fillna('NULL')\n",
    "            df_final_cancelamentos_integrais['id_placa'] = df_final_cancelamentos_integrais['id_placa'].fillna(0)\n",
    "            df_final_cancelamentos_integrais['id_veiculo'] = df_final_cancelamentos_integrais['id_veiculo'].fillna(0)\n",
    "            df_final_cancelamentos_integrais['id_carroceria'] = df_final_cancelamentos_integrais['id_carroceria'].fillna(0)\n",
    "            df_final_cancelamentos_integrais['matricula'] = df_final_cancelamentos_integrais['matricula'].fillna(0)\n",
    "            df_final_cancelamentos_integrais['conjunto'] = df_final_cancelamentos_integrais['conjunto'].fillna(0)\n",
    "            df_final_cancelamentos_integrais['unidade'] = df_final_cancelamentos_integrais['unidade'].fillna('NULL')\n",
    "            df_final_cancelamentos_integrais['status'] = df_final_cancelamentos_integrais['status'].fillna('NULL')\n",
    "            df_final_cancelamentos_integrais['cliente'] = df_final_cancelamentos_integrais['cliente'].fillna('NULL')\n",
    "            df_final_cancelamentos_integrais['data'] = df_final_cancelamentos_integrais['data'].fillna(pd.Timestamp('1900-01-01'))\n",
    "            df_final_cancelamentos_integrais['data_cancelamento'] = df_final_cancelamentos_integrais['data_cancelamento'].fillna(pd.Timestamp('1900-01-01'))\n",
    "            df_final_cancelamentos_integrais['usuario_cancelamento'] = df_final_cancelamentos_integrais['usuario_cancelamento'].fillna('NULL')\n",
    "            df_final_cancelamentos_integrais['data_filtro'] = df_final_cancelamentos_integrais['data_filtro'].fillna(pd.Timestamp('1900-01-01'))\n",
    "            df_final_cancelamentos_integrais['empresa'] = df_final_cancelamentos_integrais['empresa'].fillna('NULL')\n",
    "            df_final_cancelamentos_integrais['migracao'] = df_final_cancelamentos_integrais['migracao'].fillna('NULL')\n",
    "            df_final_cancelamentos_integrais['renegociacao'] = df_final_cancelamentos_integrais['renegociacao'].fillna('NULL')\n",
    "            df_final_cancelamentos_integrais['data_substituicao'] = df_final_cancelamentos_integrais['data_substituicao'].fillna(pd.Timestamp('1900-01-01'))\n",
    "\n",
    "            df_ativacoes_dia_anterior_ranking['placa'] = df_ativacoes_dia_anterior_ranking['placa'].fillna('SEM-PLACA')\n",
    "            df_ativacoes_dia_anterior_ranking['chassi'] = df_ativacoes_dia_anterior_ranking['chassi'].fillna('NULL')\n",
    "            df_ativacoes_dia_anterior_ranking['id_placa'] = df_ativacoes_dia_anterior_ranking['id_placa'].fillna(0)\n",
    "            df_ativacoes_dia_anterior_ranking['id_veiculo'] = df_ativacoes_dia_anterior_ranking['id_veiculo'].fillna(0)\n",
    "            df_ativacoes_dia_anterior_ranking['id_carroceria'] = df_ativacoes_dia_anterior_ranking['id_carroceria'].fillna(0)\n",
    "            df_ativacoes_dia_anterior_ranking['matricula'] = df_ativacoes_dia_anterior_ranking['matricula'].fillna(0)\n",
    "            df_ativacoes_dia_anterior_ranking['conjunto'] = df_ativacoes_dia_anterior_ranking['conjunto'].fillna(0)\n",
    "            df_ativacoes_dia_anterior_ranking['unidade'] = df_ativacoes_dia_anterior_ranking['unidade'].fillna('NULL')\n",
    "            df_ativacoes_dia_anterior_ranking['consultor'] = df_ativacoes_dia_anterior_ranking['consultor'].fillna('NULL')\n",
    "            df_ativacoes_dia_anterior_ranking['status'] = df_ativacoes_dia_anterior_ranking['status'].fillna('NULL')\n",
    "            df_ativacoes_dia_anterior_ranking['cliente'] = df_ativacoes_dia_anterior_ranking['cliente'].fillna('NULL')\n",
    "            df_ativacoes_dia_anterior_ranking['data'] = df_ativacoes_dia_anterior_ranking['data'].fillna(pd.Timestamp('1900-01-01'))\n",
    "            df_ativacoes_dia_anterior_ranking['data_ativacao'] = df_ativacoes_dia_anterior_ranking['data_ativacao'].fillna(pd.Timestamp('1900-01-01'))\n",
    "            df_ativacoes_dia_anterior_ranking['suporte'] = df_ativacoes_dia_anterior_ranking['suporte'].fillna('NULL')\n",
    "            df_ativacoes_dia_anterior_ranking['data_filtro'] = df_ativacoes_dia_anterior_ranking['data_filtro'].fillna(pd.Timestamp('1900-01-01'))\n",
    "            df_ativacoes_dia_anterior_ranking['empresa'] = df_ativacoes_dia_anterior_ranking['empresa'].fillna('NULL')\n",
    "            df_ativacoes_dia_anterior_ranking['migration_from'] = df_ativacoes_dia_anterior_ranking['migration_from'].fillna('NULL')\n",
    "            df_ativacoes_dia_anterior_ranking['coverage'] = df_ativacoes_dia_anterior_ranking['coverage'].fillna(0)\n",
    "            df_ativacoes_dia_anterior_ranking['beneficio'] = df_ativacoes_dia_anterior_ranking['beneficio'].fillna('NULL')\n",
    "            df_ativacoes_dia_anterior_ranking['categoria'] = df_ativacoes_dia_anterior_ranking['categoria'].fillna('NULL')\n",
    "            df_ativacoes_dia_anterior_ranking['tipo_categoria'] = df_ativacoes_dia_anterior_ranking['tipo_categoria'].fillna('NULL')\n",
    "            df_ativacoes_dia_anterior_ranking['data_ativacao_beneficio'] = df_ativacoes_dia_anterior_ranking['data_ativacao_beneficio'].fillna(pd.Timestamp('1900-01-01'))\n",
    "            df_ativacoes_dia_anterior_ranking['status_beneficio'] = df_ativacoes_dia_anterior_ranking['status_beneficio'].fillna('NULL')\n",
    "            df_ativacoes_dia_anterior_ranking['data_atualizacao'] = df_ativacoes_dia_anterior_ranking['data_atualizacao'].fillna(pd.Timestamp('1900-01-01'))\n",
    "            df_ativacoes_dia_anterior_ranking['microfranquia'] = df_ativacoes_dia_anterior_ranking['microfranquia'].fillna('NULL')\n",
    "            df_ativacoes_dia_anterior_ranking['id_beneficio'] = df_ativacoes_dia_anterior_ranking['id_beneficio'].fillna(0)\n",
    "        \n",
    "\n",
    "            logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "            logging.info('\\n Processo de Transformacao de Dados concluido com sucesso!')\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "            logging.info(f'Falha ao realizar tratamento de dados: {e}')\n",
    "     \n",
    "\n",
    "        return df_final_ativacoes, df_final_cancelamentos_integrais, df_ativacoes_dia_anterior_ranking\n",
    "    \n",
    "transform = Transform()\n",
    "\n",
    "df_final_ativacoes, df_final_cancelamentos_integrais, df_ativacoes_dia_anterior_ranking = transform.transforming_files()\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "edf2c632",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32984"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final_ativacoes_ativos = df_final_ativacoes[df_final_ativacoes['status_beneficio']=='ATIVO']\n",
    "df_final_ativacoes_ativos.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef4e566",
   "metadata": {},
   "source": [
    "# LOAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5bf9005b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANDO MÓDULOS E PACOTES\n",
    "import logging\n",
    "import openpyxl\n",
    "import shutil\n",
    "import os\n",
    "import traceback\n",
    "import pandas as pd\n",
    "import logging\n",
    "\n",
    "\n",
    "\n",
    "file_path = r\"C:\\Users\\raphael.almeida\\Documents\\Processos\\placas_acompanhamento\\template\\placas_movimentacoes.xlsx\"\n",
    "destination_dir = r\"C:\\Users\\raphael.almeida\\OneDrive - Grupo Unus\\analise de dados - Arquivos em excel\"\n",
    "destination_path = os.path.join(destination_dir, os.path.basename(file_path))\n",
    "\n",
    "with pd.ExcelWriter(destination_path, engine='openpyxl') as writer:\n",
    "    df_final_ativacoes.to_excel(writer, index=False, sheet_name='ATIVAÇÕES')\n",
    "    df_final_cancelamentos_integrais.to_excel(writer, index=False, sheet_name='CANCELAMENTOS')\n",
    "\n",
    "\n",
    "\n",
    "logging.info('\\n ----------------------------------------------------------------------------------')\n",
    "logging.info('\\n Processo de Carregamento de Dados concluido com sucesso!')\n",
    "\n",
    "\n",
    "\n",
    "    # extract_instance = Extract() #Fazer isso quando a class contiver instâncias \n",
    "\n",
    "    # df_ativacoes = extract_instance.extract_all_ativacoes() #salvando em variáveis os métodos da instância de classe\n",
    "    # df_cancelamentos = extract_instance.extract_all_cancelamentos() \n",
    "    # df_conferencia = extract_instance.extract_conf_boards()\n",
    "   \n",
    "    # Criando uma instância da classe Transform, pois não é uma classe estática (usa self)\n",
    "    # transform_instance = Transform()  # Passando um dicionário vazio como config\n",
    "\n",
    "    # Chamando o método transforming_files da classe Transform, que retorna os DataFrames processados    \n",
    "    # df_final_ativacoes, df_cancelamentos = transform_instance.transforming_files(df_ativacoes, df_cancelamentos, df_conferencia)\n",
    "\n",
    "    # Criando uma instância da classe Load_camp_rank_ativ, pois ela não é estática (usa self)\n",
    "    # load_instance = Load_camp_rank_ativ()\n",
    "\n",
    "    # Chamando o método load_files da instância da classe Load_camp_rank_ativ, passando os DataFrames processados\n",
    "    # load_instance.load_files(df_final_ativacoes, df_cancelamentos)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
